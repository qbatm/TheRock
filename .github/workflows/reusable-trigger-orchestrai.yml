name: Reusable OrchestrAI Trigger

on:
  workflow_call:
    inputs:
      platform:
        description: 'Platform to trigger (linux, windows, or empty for all)'
        required: false
        type: string
        default: ''
      sdk_url_override:
        description: 'Override SDK URL (skips S3 lookup, for nightly builds)'
        required: false
        type: string
        default: ''
      run_id:
        description: 'GitHub Actions workflow run ID (for bump PRs, uses install_rocm_from_artifacts.py)'
        required: false
        type: string
        default: ''
      head_sha:
        description: 'Git commit SHA from TheRock (for nightly builds)'
        required: false
        type: string
        default: ''
      pool_type:
        description: 'Jenkins agent pool type'
        required: false
        type: string
        default: 'default_hot'
      polling_interval:
        description: 'Polling interval in seconds'
        required: false
        type: number
        default: 300 # Every 5 minutes
      timeout_minutes:
        description: 'Timeout in minutes'
        required: false
        type: number
        default: 240 # 4 hour timeout
      skip_individual_summaries:
        description: 'Skip writing individual job summaries (only write consolidated summary)'
        required: false
        type: boolean
        default: true
      post_pr_comment:
        description: 'Post results as a comment on the associated PR'
        required: false
        type: boolean
        default: false
      pr_number:
        description: 'PR number to post comment to (required if post_pr_comment is true)'
        required: false
        type: string
        default: ''
      pr_repo:
        description: 'Repository for PR comment (owner/repo format, defaults to ROCm/TheRock)'
        required: false
        type: string
        default: 'ROCm/TheRock'
    secrets:
      UCICD_USER:
        required: false
      UCICD_TOKEN:
        required: false
      RP_API_TOKEN:
        required: false
      S3_ACCESS_KEY:
        required: false
      S3_SECRET_KEY:
        required: false
      THEROCK_TOKEN:
        required: false
  workflow_dispatch:
    inputs:
      platform:
        description: 'Platform filter (leave empty for all platforms)'
        required: false
        type: choice
        options:
          - ''
          - linux
          - windows
        default: ''
      sdk_url_override:
        description: 'Override SDK URL (skips S3 lookup, for nightly builds)'
        required: false
        type: string
        default: ''
      run_id:
        description: 'GitHub Actions workflow run ID (for bump PRs, uses install_rocm_from_artifacts.py)'
        required: false
        type: string
        default: ''
      head_sha:
        description: 'Git commit SHA from TheRock (for nightly builds)'
        required: false
        type: string
        default: ''
      pool_type:
        description: 'Jenkins agent pool type'
        required: false
        type: string
        default: 'default_hot'
      polling_interval:
        description: 'Polling interval in seconds'
        required: false
        type: number
        default: 300 # Every 5 minutes
      timeout_minutes:
        description: 'Timeout in minutes'
        required: false
        type: number
        default: 240 # 4 hour timeout
      skip_individual_summaries:
        description: 'Skip writing individual job summaries (only write consolidated summary)'
        required: false
        type: boolean
        default: true
      post_pr_comment:
        description: 'Post results as a comment on the associated PR'
        required: false
        type: boolean
        default: false
      pr_number:
        description: 'PR number to post comment to'
        required: false
        type: string
        default: ''
      pr_repo:
        description: 'Repository for PR comment (owner/repo format)'
        required: false
        type: string
        default: 'ROCm/TheRock'

env:
  JENKINS_URL: "https://ucicd-jenkins.amd.com"
  JENKINS_JOB_PATH: "job/ucicd-production-v1"
  REPORT_PORTAL_URL: "http://ucicd-reports-uat.amd.com:8080"
  REPORT_PORTAL_PROJECT: "ucicd_project_slim"
  S3_LOGS_BUCKET: "ucicd-therock"
  S3_LOGS_REGION: "us-east-2"

jobs:
  # Preprocessing job to generate the matrix of GPU targets
  preprocess:
    name: Generate GPU Matrix
    runs-on: arc-lnx-pub
    outputs:
      matrix: ${{ steps.generate_matrix.outputs.matrix }}
      trigger_count: ${{ steps.generate_matrix.outputs.trigger_count }}
    steps:
      - name: Checkout
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: '3.12'

      - name: Generate trigger configurations
        id: generate_matrix
        run: |
          PLATFORM_INPUT="${{ inputs.platform }}"

          # Determine which platforms to generate configs for
          if [[ -z "$PLATFORM_INPUT" ]]; then
            PLATFORMS="linux windows"
            echo "Generating OrchestrAI trigger configurations for all platforms..."
          else
            PLATFORMS="$PLATFORM_INPUT"
            echo "Generating OrchestrAI trigger configurations for $PLATFORM_INPUT..."
          fi

          # Initialize combined configs
          ALL_CONFIGS="[]"

          for PLAT in $PLATFORMS; do
            echo "Generating configs for platform: $PLAT"

            # Build the command with optional parameters
            CMD="python build_tools/trigger_orchestrai.py --mode generate --platform $PLAT"

            # Always use head_sha from TheRock when provided (for both bump PRs and nightly builds)
            if [[ -n "${{ inputs.head_sha }}" ]]; then
              CMD="$CMD --commit-id ${{ inputs.head_sha }}"
            fi

            # Add run_id if provided (for bump PRs)
            if [[ -n "${{ inputs.run_id }}" ]]; then
              CMD="$CMD --run-id \"${{ inputs.run_id }}\""
            fi

            # Add SDK URL override if provided (for nightly builds)
            if [[ -n "${{ inputs.sdk_url_override }}" ]]; then
              CMD="$CMD --sdk-url \"${{ inputs.sdk_url_override }}\""
            fi

            # Add pool type if provided
            if [[ -n "${{ inputs.pool_type }}" ]]; then
              CMD="$CMD --pool-type \"${{ inputs.pool_type }}\""
            fi

            # Use a temp file for this platform's output
            TEMP_OUTPUT=$(mktemp)
            CMD="$CMD --github-output $TEMP_OUTPUT"

            echo "Running: $CMD"
            eval $CMD

            # Read the trigger configs from temp file
            PLATFORM_CONFIGS=$(grep -oP 'trigger_configs=\K.*' $TEMP_OUTPUT || echo "[]")
            echo "  Found $(echo "$PLATFORM_CONFIGS" | jq 'length') configurations for $PLAT"

            # Merge into combined configs
            ALL_CONFIGS=$(echo "$ALL_CONFIGS" "$PLATFORM_CONFIGS" | jq -s 'add')

            rm -f $TEMP_OUTPUT
          done

          # Create matrix JSON with include array (compact single-line format)
          MATRIX=$(echo "$ALL_CONFIGS" | jq -c '{include: .}')

          # Output the matrix - use EOF delimiter for multi-line safe output
          echo "matrix=${MATRIX}" >> $GITHUB_OUTPUT

          TOTAL_COUNT=$(echo "$ALL_CONFIGS" | jq 'length')
          echo "trigger_count=${TOTAL_COUNT}" >> $GITHUB_OUTPUT

          echo "‚úÖ Matrix generated with ${TOTAL_COUNT} configurations across platforms: $PLATFORMS"

  # Matrix job that triggers each GPU target in parallel
  trigger-orchestrai:
    name: Trigger OrchestrAI (${{ matrix.platform }}/${{ matrix.gpu_tag }})
    needs: preprocess
    runs-on: arc-lnx-pub
    environment: ucicd
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.preprocess.outputs.matrix) }}
    outputs:
      # Note: Matrix jobs can't directly output arrays, so we upload results as artifacts
      result: ${{ steps.poll.outputs.result }}
    steps:
      - name: Trigger OrchestrAI
        id: trigger
        env:
          UCICD_USER: ${{ secrets.UCICD_USER }}
          UCICD_TOKEN: ${{ secrets.UCICD_TOKEN }}
          JENKINS_TRIGGER_TOKEN: ${{ secrets.UCICD_USER }}
        run: |
          echo "Triggering OrchestrAI for GPU: ${{ matrix.gpu_tag }} on ${{ matrix.platform }}"

          BUILDS_JSON='${{ matrix.builds_json }}'
          echo "BUILDS_JSON: ${BUILDS_JSON}"

          # Extract SDK URL and run_id for later use in summary
          SDK_URL='${{ matrix.sdk_url }}'
          RUN_ID='${{ matrix.run_id }}'
          echo "sdk_url=${SDK_URL}" >> $GITHUB_OUTPUT
          echo "run_id=${RUN_ID}" >> $GITHUB_OUTPUT

          # URL-encode the parameters using jq
          ENCODED_BUILDS_JSON=$(jq -rn --arg str "${BUILDS_JSON}" '$str|@uri')

          # Trigger the parameterized job using the remote trigger token
          # This bypasses CSRF protection and is the same method the old workflow used
          RESPONSE=$(curl -s -i -X POST \
            --user "${UCICD_USER}:${UCICD_TOKEN}" \
            "${{ env.JENKINS_URL }}/${{ env.JENKINS_JOB_PATH }}/buildWithParameters?token=${JENKINS_TRIGGER_TOKEN}&BUILDS_JSON=${ENCODED_BUILDS_JSON}")

          # Extract the queue URL from Location header
          QUEUE_URL=$(echo "$RESPONSE" | grep -i "^Location:" | awk '{print $2}' | tr -d '\r')

          if [ -z "$QUEUE_URL" ]; then
            echo "::error::Failed to trigger OrchestrAI for ${{ matrix.gpu_tag }}"
            echo "Response:"
            echo "$RESPONSE" | head -30
            exit 1
          fi

          echo "Queue URL: $QUEUE_URL"
          echo "queue_url=${QUEUE_URL}" >> $GITHUB_OUTPUT

      - name: Wait for Build Number
        id: get_build_number
        env:
          UCICD_USER: ${{ secrets.UCICD_USER }}
          UCICD_TOKEN: ${{ secrets.UCICD_TOKEN }}
        run: |
          QUEUE_URL="${{ steps.trigger.outputs.queue_url }}"

          echo "Waiting for OrchestrAI build (${{ matrix.gpu_tag }}) to be assigned..."

          # Poll the queue until we get a build number (max 5 minutes)
          MAX_ATTEMPTS=60
          ATTEMPT=0
          BUILD_NUMBER=""

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            QUEUE_INFO=$(curl -s --user "${UCICD_USER}:${UCICD_TOKEN}" \
              "${QUEUE_URL}api/json")

            # Check if build has started (executable field will be populated) using jq
            BUILD_NUMBER=$(echo "$QUEUE_INFO" | jq -r '.executable.number // empty')

            if [ -n "$BUILD_NUMBER" ]; then
              echo "Build number: $BUILD_NUMBER"
              break
            fi

            # Check if cancelled using jq
            CANCELLED=$(echo "$QUEUE_INFO" | jq -r '.cancelled // false')

            if [ "$CANCELLED" = "true" ]; then
              echo "::error::OrchestrAI build (${{ matrix.gpu_tag }}) was cancelled in queue"
              exit 1
            fi

            ATTEMPT=$((ATTEMPT + 1))
            echo "Waiting for build to start (attempt $ATTEMPT/$MAX_ATTEMPTS)..."
            sleep 5
          done

          if [ -z "$BUILD_NUMBER" ]; then
            echo "::error::Timed out waiting for OrchestrAI build number (${{ matrix.gpu_tag }})"
            exit 1
          fi

          echo "build_number=${BUILD_NUMBER}" >> $GITHUB_OUTPUT

      - name: Poll OrchestrAI for Completion
        id: poll
        env:
          UCICD_USER: ${{ secrets.UCICD_USER }}
          UCICD_TOKEN: ${{ secrets.UCICD_TOKEN }}
          BUILD_NUMBER: ${{ steps.get_build_number.outputs.build_number }}
        run: |
          BUILD_URL="${{ env.JENKINS_URL }}/${{ env.JENKINS_JOB_PATH }}/${BUILD_NUMBER}"
          echo "Polling OrchestrAI build: ${BUILD_NUMBER} (${{ matrix.gpu_tag }})"

          POLLING_INTERVAL=${{ inputs.polling_interval }}
          TIMEOUT_SECONDS=$(( ${{ inputs.timeout_minutes }} * 60 ))
          START_TIME=$(date +%s)

          while true; do
            CURRENT_TIME=$(date +%s)
            ELAPSED=$((CURRENT_TIME - START_TIME))

            if [ $ELAPSED -ge $TIMEOUT_SECONDS ]; then
              echo "::error::Timeout waiting for OrchestrAI (${{ matrix.platform }}/${{ matrix.gpu_tag }}) to complete"
              echo "result=TIMEOUT" >> $GITHUB_OUTPUT
              echo "duration=${ELAPSED}s" >> $GITHUB_OUTPUT
              exit 1
            fi

            BUILD_INFO=$(curl -s --user "${UCICD_USER}:${UCICD_TOKEN}" \
              "${BUILD_URL}/api/json")

            # Check if build is still running using jq
            BUILDING=$(echo "$BUILD_INFO" | jq -r 'if .building == false then "false" else "true" end')

            if [ "$BUILDING" = "false" ]; then
              echo "OrchestrAI build completed!"

              # Extract result using jq
              RESULT=$(echo "$BUILD_INFO" | jq -r '.result // "UNKNOWN"')

              # Extract duration and convert to seconds using jq
              DURATION_MS=$(echo "$BUILD_INFO" | jq -r '.duration // 0')
              DURATION_SEC=$((DURATION_MS / 1000))

              echo "result=${RESULT}" >> $GITHUB_OUTPUT
              echo "duration=${DURATION_SEC}s" >> $GITHUB_OUTPUT
              break
            fi

            echo "Build still running (${{ matrix.gpu_tag }})... (elapsed: ${ELAPSED}s)"
            sleep $POLLING_INTERVAL
          done

      - name: Fetch Test Results
        id: test_results
        env:
          UCICD_USER: ${{ secrets.UCICD_USER }}
          UCICD_TOKEN: ${{ secrets.UCICD_TOKEN }}
          BUILD_NUMBER: ${{ steps.get_build_number.outputs.build_number }}
        run: |
          BUILD_URL="${{ env.JENKINS_URL }}/${{ env.JENKINS_JOB_PATH }}/${BUILD_NUMBER}"
          echo "Fetching test results from OrchestrAI build ${BUILD_NUMBER}..."

          # Try to fetch the test results JSON artifact from Jenkins workspace
          # The file is written as ucicd_test_results.json by the pipeline
          TEST_RESULTS=$(curl -s --user "${UCICD_USER}:${UCICD_TOKEN}" \
            "${BUILD_URL}/artifact/ucicd_test_results.json" 2>/dev/null || echo "")

          if [ -n "$TEST_RESULTS" ] && echo "$TEST_RESULTS" | jq -e '.summary' > /dev/null 2>&1; then
            echo "‚úÖ Test results fetched successfully"

            # Extract test summary fields
            PLATFORM=$(echo "$TEST_RESULTS" | jq -r '.summary.environment.THEROCK_PLATFORM // "N/A"')
            GPU_ARCH=$(echo "$TEST_RESULTS" | jq -r '.summary.environment.THEROCK_GPU_ARCH_PATTERN // "N/A"')
            TOTAL_TESTS=$(echo "$TEST_RESULTS" | jq -r '.summary.total_tests // "N/A"')
            PASSED=$(echo "$TEST_RESULTS" | jq -r '.summary.passed // "N/A"')
            FAILED=$(echo "$TEST_RESULTS" | jq -r '.summary.failed // "N/A"')
            SKIPPED=$(echo "$TEST_RESULTS" | jq -r '.summary.skipped // "N/A"')
            ERROR=$(echo "$TEST_RESULTS" | jq -r '.summary.error // "N/A"')
            UNKNOWN=$(echo "$TEST_RESULTS" | jq -r '.summary.unknown // "N/A"')

            # Try to extract ReportPortal launch name/ID from test results
            # The launch name is typically stored in the results or can be derived
            RP_LAUNCH_NAME=$(echo "$TEST_RESULTS" | jq -r '.summary.rp_launch_name // .rp_launch_name // ""')
            RP_LAUNCH_ID=$(echo "$TEST_RESULTS" | jq -r '.summary.rp_launch_id // .rp_launch_id // ""')

            # Output for use in summary step
            echo "has_results=true" >> $GITHUB_OUTPUT
            echo "platform=${PLATFORM}" >> $GITHUB_OUTPUT
            echo "gpu_arch=${GPU_ARCH}" >> $GITHUB_OUTPUT
            echo "total_tests=${TOTAL_TESTS}" >> $GITHUB_OUTPUT
            echo "passed=${PASSED}" >> $GITHUB_OUTPUT
            echo "failed=${FAILED}" >> $GITHUB_OUTPUT
            echo "skipped=${SKIPPED}" >> $GITHUB_OUTPUT
            echo "error=${ERROR}" >> $GITHUB_OUTPUT
            echo "unknown=${UNKNOWN}" >> $GITHUB_OUTPUT
            echo "rp_launch_name=${RP_LAUNCH_NAME}" >> $GITHUB_OUTPUT
            echo "rp_launch_id=${RP_LAUNCH_ID}" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è Test results not available or invalid format"
            echo "has_results=false" >> $GITHUB_OUTPUT
          fi

      - name: Scrape ReportPortal URL from Jenkins Summary
        id: scrape_rp
        if: ${{ steps.test_results.outputs.rp_launch_id == '' }}
        env:
          UCICD_USER: ${{ secrets.UCICD_USER }}
          UCICD_TOKEN: ${{ secrets.UCICD_TOKEN }}
          BUILD_NUMBER: ${{ steps.get_build_number.outputs.build_number }}
        run: |
          BUILD_URL="${{ env.JENKINS_URL }}/${{ env.JENKINS_JOB_PATH }}/${BUILD_NUMBER}"
          echo "Scraping ReportPortal URL from Jenkins summary HTML..."

          # Fetch the Jenkins build summary page
          SUMMARY_HTML=$(curl -s --user "${UCICD_USER}:${UCICD_TOKEN}" \
            "${BUILD_URL}/" 2>/dev/null || echo "")

          if [ -n "$SUMMARY_HTML" ]; then
            # Extract ReportPortal URL from the summary HTML
            # The URL format is: http://ucicd-reports-uat.amd.com:8080/ui/#ucicd_project_slim/launches/all/{launch_id}
            RP_URL=$(echo "$SUMMARY_HTML" | grep -oP 'href="[^"]*ucicd-reports[^"]*launches/all/\d+[^"]*"' | head -1 | sed 's/href="//;s/"$//')

            if [ -n "$RP_URL" ]; then
              echo "‚úÖ Found ReportPortal URL: ${RP_URL}"

              # Extract the launch ID from the URL (numeric ID at the end)
              RP_LAUNCH_ID=$(echo "$RP_URL" | grep -oP 'launches/all/\K\d+')

              if [ -n "$RP_LAUNCH_ID" ]; then
                echo "‚úÖ Extracted ReportPortal Launch ID: ${RP_LAUNCH_ID}"
                echo "rp_launch_id=${RP_LAUNCH_ID}" >> $GITHUB_OUTPUT
                echo "rp_launch_url=${RP_URL}" >> $GITHUB_OUTPUT
              else
                echo "‚ö†Ô∏è Could not extract launch ID from URL"
              fi
            else
              echo "‚ö†Ô∏è ReportPortal URL not found in Jenkins summary"
            fi
          else
            echo "‚ö†Ô∏è Could not fetch Jenkins summary page"
          fi

      - name: Save Results for Consolidated Summary
        id: save_results
        if: always()
        run: |
          # Create a JSON file with this job's results for the consolidated summary
          mkdir -p results

          # Handle case where result might not be set (e.g., earlier failure)
          RESULT="${{ steps.poll.outputs.result }}"
          if [ -z "$RESULT" ]; then
            RESULT="ERROR"
          fi

          # Use RP launch ID from test results, or fall back to scraped value
          RP_LAUNCH_ID="${{ steps.test_results.outputs.rp_launch_id }}"
          if [ -z "$RP_LAUNCH_ID" ]; then
            RP_LAUNCH_ID="${{ steps.scrape_rp.outputs.rp_launch_id }}"
          fi

          RP_LAUNCH_URL="${{ steps.scrape_rp.outputs.rp_launch_url }}"

          cat > results/${{ matrix.platform }}-${{ matrix.gpu_tag }}.json << EOF
          {
            "gpu_tag": "${{ matrix.gpu_tag }}",
            "platform": "${{ matrix.platform }}",
            "sdk_url": "${{ steps.trigger.outputs.sdk_url }}",
            "run_id": "${{ steps.trigger.outputs.run_id }}",
            "build_number": "${{ steps.get_build_number.outputs.build_number }}",
            "result": "${RESULT}",
            "duration": "${{ steps.poll.outputs.duration }}",
            "has_results": "${{ steps.test_results.outputs.has_results }}",
            "test_platform": "${{ steps.test_results.outputs.platform }}",
            "test_gpu_arch": "${{ steps.test_results.outputs.gpu_arch }}",
            "total_tests": "${{ steps.test_results.outputs.total_tests }}",
            "passed": "${{ steps.test_results.outputs.passed }}",
            "failed": "${{ steps.test_results.outputs.failed }}",
            "skipped": "${{ steps.test_results.outputs.skipped }}",
            "error": "${{ steps.test_results.outputs.error }}",
            "unknown": "${{ steps.test_results.outputs.unknown }}",
            "rp_launch_name": "${{ steps.test_results.outputs.rp_launch_name }}",
            "rp_launch_id": "${RP_LAUNCH_ID}",
            "rp_launch_url": "${RP_LAUNCH_URL}"
          }
          EOF
          echo "Saved results for ${{ matrix.platform }}/${{ matrix.gpu_tag }}"

      - name: Upload Results Artifact
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: orchestrai-results-${{ matrix.platform }}-${{ matrix.gpu_tag }}
          path: results/${{ matrix.platform }}-${{ matrix.gpu_tag }}.json
          retention-days: 1

      - name: Write Job Summary
        if: ${{ inputs.skip_individual_summaries != true }}
        run: |
          RESULT="${{ steps.poll.outputs.result }}"
          SDK_URL="${{ steps.trigger.outputs.sdk_url }}"
          RUN_ID="${{ steps.trigger.outputs.run_id }}"
          GPU_TAG="${{ matrix.gpu_tag }}"
          PLATFORM="${{ matrix.platform }}"

          # Write summary with GPU target context
          echo "### OrchestrAI Test Results - ${GPU_TAG} (${PLATFORM})" >> $GITHUB_STEP_SUMMARY

          # Add test results table if available
          if [ "${{ steps.test_results.outputs.has_results }}" = "true" ]; then
            echo "| Platform | GPU Arch | Total Tests | Passed | Failed | Skipped | Error | Unknown |" >> $GITHUB_STEP_SUMMARY
            echo "|----------|----------|-------------|--------|--------|---------|-------|---------|" >> $GITHUB_STEP_SUMMARY
            echo "| ${{ steps.test_results.outputs.platform }} | ${{ steps.test_results.outputs.gpu_arch }} | ${{ steps.test_results.outputs.total_tests }} | ${{ steps.test_results.outputs.passed }} | ${{ steps.test_results.outputs.failed }} | ${{ steps.test_results.outputs.skipped }} | ${{ steps.test_results.outputs.error }} | ${{ steps.test_results.outputs.unknown }} |" >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "_Test results not available_" >> $GITHUB_STEP_SUMMARY
          fi

          # Add source info (SDK URL or Run ID)
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -n "$RUN_ID" ]; then
            echo "**TheRock Run ID:** [${RUN_ID}](https://github.com/ROCm/TheRock/actions/runs/${RUN_ID})" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -n "$SDK_URL" ]; then
            echo "**SDK URL:** ${SDK_URL}" >> $GITHUB_STEP_SUMMARY
          fi

      # For now, don't fail for
      # - name: Check Result
      #   run: |
      #     RESULT="${{ steps.poll.outputs.result }}"
      #     GPU_TAG="${{ matrix.gpu_tag }}"

      #     # Fail the workflow if OrchestrAI job failed
      #     if [ "$RESULT" != "SUCCESS" ]; then
      #       echo "::error::OrchestrAI (${GPU_TAG}) finished with result: ${RESULT}"
      #       exit 1
      #     fi

  # Consolidated summary job that combines all matrix results
  consolidated-summary:
    name: Consolidated Summary
    needs: [preprocess, trigger-orchestrai]
    if: always()
    runs-on: arc-lnx-pub
    environment: ucicd
    steps:
      - name: Checkout
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
        with:
          python-version: '3.12'

      - name: Install Python dependencies
        run: |
          pip install requests boto3

      - name: Download All Results
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        continue-on-error: true
        with:
          pattern: orchestrai-results-*
          path: results
          merge-multiple: true

      - name: Check Results
        id: check_results
        run: |
          if [ -d results ] && [ -n "$(ls -A results 2>/dev/null)" ]; then
            echo "has_results=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Found result files:"
            ls -la results/
          else
            echo "has_results=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è No result files found (matrix jobs may not have completed)"
            mkdir -p results
          fi

      - name: Download Logs from ReportPortal
        id: download_logs
        if: ${{ steps.check_results.outputs.has_results == 'true' }}
        env:
          RP_API_TOKEN: ${{ secrets.RP_API_TOKEN }}
          REPORT_PORTAL_URL: ${{ env.REPORT_PORTAL_URL }}
          REPORT_PORTAL_PROJECT: ${{ env.REPORT_PORTAL_PROJECT }}
        run: |
          # Skip if RP_API_TOKEN is not configured
          if [ -z "$RP_API_TOKEN" ]; then
            echo "‚ö†Ô∏è RP_API_TOKEN not configured, skipping ReportPortal log download"
            echo "has_logs=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "‚úÖ RP_API_TOKEN is configured"
          echo "Downloading logs from ReportPortal..."
          mkdir -p aggregated_logs

          # Debug: List result files
          echo "Result files found:"
          ls -la results/ || echo "No results directory"

          # Process each result file to get RP launch info
          for result_file in results/*.json; do
            if [ -f "$result_file" ]; then
              echo "Processing: $result_file"
              cat "$result_file"

              GPU_TAG=$(jq -r '.gpu_tag // ""' "$result_file")
              PLATFORM=$(jq -r '.platform // ""' "$result_file")
              RP_LAUNCH_NAME=$(jq -r '.rp_launch_name // ""' "$result_file")
              RP_LAUNCH_ID=$(jq -r '.rp_launch_id // ""' "$result_file")

              echo "  GPU_TAG: $GPU_TAG, PLATFORM: $PLATFORM"
              echo "  RP_LAUNCH_ID: $RP_LAUNCH_ID, RP_LAUNCH_NAME: $RP_LAUNCH_NAME"

              # Prefer launch ID (scraped from Jenkins summary) over launch name
              if [ -n "$RP_LAUNCH_ID" ]; then
                echo "Downloading logs for ${PLATFORM}/${GPU_TAG} (launch ID: ${RP_LAUNCH_ID})..."
                python build_tools/download_rp_logs.py \
                  --launch-id "$RP_LAUNCH_ID" \
                  --output "aggregated_logs/${PLATFORM}_${GPU_TAG}" \
                  --debug \
                  2>&1 || echo "‚ö†Ô∏è Failed to download logs for launch ID ${RP_LAUNCH_ID}"
              elif [ -n "$RP_LAUNCH_NAME" ]; then
                echo "Downloading logs for ${PLATFORM}/${GPU_TAG} (launch name: ${RP_LAUNCH_NAME})..."
                python build_tools/download_rp_logs.py \
                  --launch-name "$RP_LAUNCH_NAME" \
                  --output "aggregated_logs/${PLATFORM}_${GPU_TAG}" \
                  --debug \
                  2>&1 || echo "‚ö†Ô∏è Failed to download logs for ${RP_LAUNCH_NAME}"
              else
                echo "‚ö†Ô∏è No ReportPortal launch info for ${PLATFORM}/${GPU_TAG}"
              fi
            fi
          done

          # Check if we downloaded any logs
          echo "Checking aggregated_logs directory..."
          ls -laR aggregated_logs/ 2>/dev/null || echo "aggregated_logs is empty or doesn't exist"

          # Count files (excluding directories)
          FILE_COUNT=$(find aggregated_logs -type f 2>/dev/null | wc -l)
          echo "Found ${FILE_COUNT} files in aggregated_logs"

          # Also check for non-empty directories as a fallback
          DIR_COUNT=$(find aggregated_logs -mindepth 1 -type d 2>/dev/null | wc -l)
          echo "Found ${DIR_COUNT} subdirectories in aggregated_logs"

          if [ "$FILE_COUNT" -gt 0 ]; then
            echo "has_logs=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Downloaded ${FILE_COUNT} log files"
          else
            echo "has_logs=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è No log files downloaded (directories may exist but are empty)"
          fi

      - name: Upload Logs to S3
        id: upload_s3
        if: ${{ always() && steps.download_logs.outputs.has_logs == 'true' }}
        env:
          # Map secret names to standard AWS environment variable names
          AWS_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_KEY }}
          AWS_DEFAULT_REGION: ${{ env.S3_LOGS_REGION }}
        run: |
          # Skip if AWS credentials are not configured
          if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ]; then
            echo "‚ö†Ô∏è AWS credentials not configured, skipping S3 upload"
            echo "s3_url=" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Uploading logs to S3..."

          # Generate S3 key matching pattern: PR{number}_ID{run_id}_{timestamp}.zip
          # Example: PR2555_ID20245985754_20251217183045.zip
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          RUN_ID="${{ github.run_id }}"

          # Try to extract PR number from run title or use 'Run' as fallback
          PR_NUM="Run"
          if [[ "${{ github.event.head_commit.message }}" =~ PR[[:space:]]*#?([0-9]+) ]]; then
            PR_NUM="PR${BASH_REMATCH[1]}"
          fi

          S3_KEY="${PR_NUM}_ID${RUN_ID}_${TIMESTAMP}.zip"

          # Upload to S3 using AWS CLI
          python build_tools/upload_logs_to_s3.py \
            --log-dir aggregated_logs \
            --bucket "${{ env.S3_LOGS_BUCKET }}" \
            --s3-key "$S3_KEY" \
            --region "${{ env.S3_LOGS_REGION }}" \
            2>&1

          if [ $? -eq 0 ]; then
            # Generate the HTTPS URL for the summary
            S3_URL="https://${{ env.S3_LOGS_BUCKET }}.s3.${{ env.S3_LOGS_REGION }}.amazonaws.com/${S3_KEY}"
            echo "s3_url=${S3_URL}" >> $GITHUB_OUTPUT
            echo "‚úÖ Logs uploaded to ${S3_URL}"
          else
            echo "‚ùå Failed to upload logs to S3"
            echo "s3_url=" >> $GITHUB_OUTPUT
          fi

      - name: Write Summary and Post PR Comment
        env:
          GH_TOKEN: ${{ secrets.THEROCK_TOKEN }}
          S3_URL: ${{ steps.upload_s3.outputs.s3_url }}
          PR_NUMBER: ${{ inputs.pr_number }}
          PR_REPO: ${{ inputs.pr_repo }}
          POST_PR_COMMENT: ${{ inputs.post_pr_comment }}
        run: |
          # Generate summary content
          SUMMARY_FILE="summary_content.md"
          HAS_RESULTS="false"

          # Check if we have any results
          if [ ! -d results ] || [ -z "$(ls -A results 2>/dev/null)" ]; then
            echo "_No test results available_" > "$SUMMARY_FILE"
          else
            HAS_RESULTS="true"

            # Create the table header
            echo "| GPU Target | Platform | Result | Total Tests | Passed | Failed | Skipped | Error | Unknown |" > "$SUMMARY_FILE"
            echo "|------------|----------|--------|-------------|--------|--------|---------|-------|---------|" >> "$SUMMARY_FILE"

            # Track additional info
            RUN_IDS=""
            RP_LAUNCH_URLS=""

            # Process each result file
            for result_file in results/*.json; do
              if [ -f "$result_file" ]; then
                GPU_TAG=$(jq -r '.gpu_tag // "N/A"' "$result_file")
                PLATFORM=$(jq -r '.platform // "N/A"' "$result_file")
                RESULT=$(jq -r '.result // "UNKNOWN"' "$result_file")
                RUN_ID=$(jq -r '.run_id // ""' "$result_file")
                HAS_TEST_RESULTS=$(jq -r '.has_results // "false"' "$result_file")
                RP_LAUNCH_URL=$(jq -r '.rp_launch_url // ""' "$result_file")

                # Format result with emoji
                # TODO: Hardcoded - if 0 tests were run, ignore downstream result and show as skipped
                if [ "$HAS_TEST_RESULTS" = "true" ]; then
                  TOTAL_CHECK=$(jq -r '.total_tests // "0"' "$result_file")
                  if [ "$TOTAL_CHECK" = "0" ] || [ "$TOTAL_CHECK" = "-" ] || [ "$TOTAL_CHECK" = "N/A" ]; then
                    RESULT_DISPLAY="‚è≠Ô∏è SKIPPED"
                  elif [ "$RESULT" = "SUCCESS" ]; then
                    RESULT_DISPLAY="‚úÖ SUCCESS"
                  elif [ "$RESULT" = "FAILURE" ]; then
                    RESULT_DISPLAY="‚ùå FAILURE"
                  elif [ "$RESULT" = "TIMEOUT" ]; then
                    RESULT_DISPLAY="‚è±Ô∏è TIMEOUT"
                  elif [ "$RESULT" = "ERROR" ]; then
                    RESULT_DISPLAY="üí• ERROR"
                  else
                    RESULT_DISPLAY="‚ö†Ô∏è ${RESULT}"
                  fi
                elif [ "$RESULT" = "SUCCESS" ]; then
                  RESULT_DISPLAY="‚úÖ SUCCESS"
                elif [ "$RESULT" = "FAILURE" ]; then
                  RESULT_DISPLAY="‚ùå FAILURE"
                elif [ "$RESULT" = "TIMEOUT" ]; then
                  RESULT_DISPLAY="‚è±Ô∏è TIMEOUT"
                elif [ "$RESULT" = "ERROR" ]; then
                  RESULT_DISPLAY="üí• ERROR"
                else
                  RESULT_DISPLAY="‚ö†Ô∏è ${RESULT}"
                fi

                # GPU tag display
                GPU_TAG_DISPLAY="${GPU_TAG}"

                if [ "$HAS_TEST_RESULTS" = "true" ]; then
                  TOTAL=$(jq -r '.total_tests // "-"' "$result_file")
                  PASSED=$(jq -r '.passed // "-"' "$result_file")
                  FAILED=$(jq -r '.failed // "-"' "$result_file")
                  SKIPPED=$(jq -r '.skipped // "-"' "$result_file")
                  ERROR=$(jq -r '.error // "-"' "$result_file")
                  UNKNOWN=$(jq -r '.unknown // "-"' "$result_file")
                else
                  TOTAL="-"
                  PASSED="-"
                  FAILED="-"
                  SKIPPED="-"
                  ERROR="-"
                  UNKNOWN="-"
                fi

                # Add table row
                echo "| ${GPU_TAG_DISPLAY} | ${PLATFORM} | ${RESULT_DISPLAY} | ${TOTAL} | ${PASSED} | ${FAILED} | ${SKIPPED} | ${ERROR} | ${UNKNOWN} |" >> "$SUMMARY_FILE"

                # Collect unique Run IDs
                if [ -n "$RUN_ID" ] && [[ ! "$RUN_IDS" =~ "$RUN_ID" ]]; then
                  RUN_IDS="${RUN_IDS}${RUN_ID}\n"
                fi

                # Collect ReportPortal launch URLs with GPU tag context
                if [ -n "$RP_LAUNCH_URL" ]; then
                  RP_LAUNCH_URLS="${RP_LAUNCH_URLS}${PLATFORM}/${GPU_TAG}|${RP_LAUNCH_URL}\n"
                fi
              fi
            done

            # Save collected data
            echo -e "$RUN_IDS" > run_ids.txt
            echo -e "$RP_LAUNCH_URLS" > rp_urls.txt
          fi

          # === Write Step Summary ===
          echo "### OrchestrAI Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat "$SUMMARY_FILE" >> $GITHUB_STEP_SUMMARY

          if [ "$HAS_RESULTS" = "true" ]; then
            # Add TheRock Run IDs section (for bump PRs)
            if [ -f run_ids.txt ] && [ -s run_ids.txt ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "#### TheRock Run IDs" >> $GITHUB_STEP_SUMMARY
              while read -r run_id; do
                if [ -n "$run_id" ]; then
                  echo "- [${run_id}](https://github.com/ROCm/TheRock/actions/runs/${run_id})" >> $GITHUB_STEP_SUMMARY
                fi
              done < run_ids.txt
            fi

            # Add S3 Logs section
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "#### S3 Logs" >> $GITHUB_STEP_SUMMARY
            if [ -n "$S3_URL" ]; then
              echo "üì¶ [Complete S3 Logs](${S3_URL})" >> $GITHUB_STEP_SUMMARY
            else
              echo "_No logs available (ReportPortal or S3 credentials not configured)_" >> $GITHUB_STEP_SUMMARY
            fi
          fi

          # === Post PR Comment ===
          if [ "$POST_PR_COMMENT" != "true" ] || [ -z "$PR_NUMBER" ]; then
            echo "Skipping PR comment (post_pr_comment=$POST_PR_COMMENT, pr_number=$PR_NUMBER)"
            exit 0
          fi

          if [ -z "$GH_TOKEN" ]; then
            echo "‚ö†Ô∏è THEROCK_TOKEN not configured, skipping PR comment"
            exit 0
          fi

          echo "Posting results to PR #${PR_NUMBER} in ${PR_REPO}..."

          # Build the comment body file (same content as step summary)
          COMMENT_FILE="pr_comment.md"
          cat > "$COMMENT_FILE" << 'EOF'
          ## OrchestrAI Test Results Summary
          EOF

          # Add the same table
          cat "$SUMMARY_FILE" >> "$COMMENT_FILE"

          if [ "$HAS_RESULTS" = "true" ]; then
            # Add TheRock Run IDs section
            if [ -f run_ids.txt ] && [ -s run_ids.txt ]; then
              echo "" >> "$COMMENT_FILE"
              echo "#### TheRock Run IDs" >> "$COMMENT_FILE"
              while read -r run_id; do
                if [ -n "$run_id" ]; then
                  echo "- [${run_id}](https://github.com/ROCm/TheRock/actions/runs/${run_id})" >> "$COMMENT_FILE"
                fi
              done < run_ids.txt
            fi

            # Add S3 logs link if available
            if [ -n "$S3_URL" ]; then
              echo "" >> "$COMMENT_FILE"
              echo "üì¶ [Complete S3 Logs](${S3_URL})" >> "$COMMENT_FILE"
            fi
          fi

          # Add footer
          echo "" >> "$COMMENT_FILE"
          echo "---" >> "$COMMENT_FILE"
          echo "<sub>Posted by OrchestrAI workflow</sub>" >> "$COMMENT_FILE"

          # # Post comment using gh api
          # echo "Creating new comment..."
          # gh api \
          #   --method POST \
          #   -H "Accept: application/vnd.github+json" \
          #   "/repos/${PR_REPO}/issues/${PR_NUMBER}/comments" \
          #   -F body=@"$COMMENT_FILE"
          # echo "‚úÖ Posted PR comment"

          # Post comment using curl (gh CLI may not be available on custom runners)
          echo "Creating new comment..."
          echo "Creating comment on repo ${PR_REPO}, PR #${PR_NUMBER}"
          RESPONSE=$(curl -s -X POST \
            -H "Authorization: token ${GH_TOKEN}" \
            -H "Accept: application/vnd.github+json" \
            -H "Content-Type: application/json" \
            "https://api.github.com/repos/qbatm/TheRock/issues/255/comments" \
            -d "$(jq -n --rawfile body "$COMMENT_FILE" '{body: $body}')")

          if echo "$RESPONSE" | jq -e '.id' > /dev/null 2>&1; then
            COMMENT_URL=$(echo "$RESPONSE" | jq -r '.html_url')
            echo "‚úÖ Posted PR comment: ${COMMENT_URL}"
          else
            echo "‚ùå Failed to post PR comment"
            echo "$RESPONSE"
            exit 1
          fi
